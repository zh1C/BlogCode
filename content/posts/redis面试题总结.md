---
author: "Narcissus"
title: "Redis面试题总结"
date: "2022-02-17"
lastmod: "2022-02-17"
description: "redis相关面试题总结"
tags: ["Redis", "面试总结"]
categories: ["Redis学习"]
---

## 认识Redis

### 什么是Redis？

Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此**读写速度非常快**，常用于**缓存，消息队列、分布式锁等场景**。

Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是**原子性**的，因为执行命令由单线程负责的，不存在并发竞争的问题。

****

### Redis和Memcached有什么区别？

Redis 与 Memcached **共同点**：

1. 都是基于内存的数据库，一般都用来当做缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

Redis 与 Memcached **区别**：

- Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；
- Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；
- Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；
- Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；

****

### 为什么用Redis作为MySQL的缓存？

主要是因为 **Redis 具备「高性能」和「高并发」两种特性**。

> 1. Redis具有高性能
>
> 假如用户第一次访问 MySQL 中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作 Redis 缓存就是直接操作内存，所以速度相当快。
>
> 2. Redis具有高并发
>
> 单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。

****

## Redis数据类型及应用场景

### String

#### 介绍

String 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值，value其实不仅是字符串， 也可以是数字（整数或浮点数），value 最多可以容纳的数据长度是 `512M`。

#### 内部实现

String 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。

> SDS与C字符串的区别
>
> - **SDS 不仅可以保存文本数据，还可以保存二进制数据**。因为 `SDS` 使用 `len` 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 `buf[]` 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。
> - **SDS 获取字符串长度的时间复杂度是 O(1)**。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 `len` 属性记录了字符串长度，所以复杂度为 `O(1)`。
> - **Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出**。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。

字符串对象的内部编码（encoding）有 3 种 ：**int、raw和 embstr**。

![image-20230221091133814](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230221091133814.png)

> - 如果一个字符串对象保存的是整数值，并且这个整数值可以用`long`类型来表示，那么字符串编码将设置为`int`。
> - 如果字符串对象保存的是一个字符串，并且这个字符申的长度小于等于 32 字节（redis 2.+版本），编码将设置为`embstr`。
> - 如果字符串对象保存的是一个字符串，并且这个字符串的长度大于 32 字节（redis 2.+版本），编码将设置为`raw`。
>
> 不同之处在于`embstr`会通过一次内存分配函数来分配一块连续的内存空间来保存`redisObject`和`SDS`，而`raw`编码会通过调用两次内存分配函数来分别分配两块空间来保存`redisObject`和`SDS`。
>
> 这样的好处是：将内存分配和释放降低为一次，并且`embstr`编码所有数据保存在一块连续内存能更好利用CPU缓存提升性能。
>
> 缺陷就是：**embstr编码的字符串对象实际上是只读的**，我们对embstr编码的字符串对象执行任何修改命令（例如append）时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。

****

#### 常用命令

基本操作

```shell
# 设置 key-value 类型的值
> SET name lin
OK
# 根据 key 获得对应的 value
> GET name
"lin"
# 判断某个 key 是否存在
> EXISTS name
(integer) 1
# 返回 key 所储存的字符串值的长度
> STRLEN name
(integer) 3
# 删除某个 key 对应的值
> DEL name
(integer) 1
```

批量设置

```shell
# 批量设置 key-value 类型的值
> MSET key1 value1 key2 value2 
OK
# 批量获取多个 key 对应的 value
> MGET key1 key2 
1) "value1"
2) "value2"
```

计数器（字符串的内容为整数的时候可以使用）：

```shell
# 设置 key-value 类型的值
> SET number 0
OK
# 将 key 中储存的数字值增一
> INCR number
(integer) 1
# 将key中存储的数字值加 10
> INCRBY number 10
(integer) 11
# 将 key 中储存的数字值减一
> DECR number
(integer) 10
# 将key中存储的数字值键 10
> DECRBY number 10
(integer) 0
```

过期（默认为永不过期）：

```shell
# 设置 key 在 60 秒后过期（该方法是针对已经存在的key设置过期时间）
> EXPIRE name  60 
(integer) 1
# 查看数据还有多久过期
> TTL name 
(integer) 51
#设置 key-value 类型的值，并设置该key的过期时间为 60 秒
> SET key  value EX 60
OK
> SETEX key  60 value
OK
```

不存在就插入：

```shell
# 不存在就插入（not exists）
>SETNX key value
(integer) 1
```

****

#### 应用场景

可用作：**缓存对象、常规计数、分布式锁和共享Session信息等**。

- **缓存对象**

使用 String 来缓存对象有两种方式：

> 1. 直接缓存整个对象的 JSON，命令例子： `SET user:1 '{"name":"xiaolin", "age":18}'`。
> 2. 采用将 key 进行分离为 user:ID:属性，采用 MSET 存储，用 MGET 获取各属性值，命令例子： `MSET user:1:name xiaolin user:1:age 18 user:2:name xiaomei user:2:age 20`。

- **常规计数**

因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等。如下计算文章阅读量：

```shell
# 初始化文章的阅读量
> SET aritcle:readcount:1001 0
OK
#阅读量+1
> INCR aritcle:readcount:1001
(integer) 1
#阅读量+1
> INCR aritcle:readcount:1001
(integer) 2
#阅读量+1
> INCR aritcle:readcount:1001
(integer) 3
# 获取对应文章的阅读量
> GET aritcle:readcount:1001
"3"
```

- **分布式锁**

SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁：

> 分布式加锁命令`SET lock_key unique_value NX PX 10000`，设置了锁的过期时间。
>
> - 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
> - 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。
>
> 解锁需要通过lua脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。

- **共享Session信息**

通常我们在开发后台管理系统时，会使用 Session 来保存用户的会话(登录)状态，这些 Session 信息会被保存在服务器端，但对于分布式系统，可能出现该服务器没有用户的Session信息，重复登录的情况。因此使用同一个 Redis 存储 Session。

![image-20230221093312020](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230221093312020.png)

****

****

### List

#### 介绍

List 列表是简单的字符串列表，**按照插入顺序排序**，可以从头部或尾部向 List 列表添加元素。

#### 内部实现

List 类型的底层数据结构是由**双向链表或压缩列表**实现的：

- 如果列表的元素个数小于 `512` 个（默认值，可由 `list-max-ziplist-entries` 配置），列表每个元素的值都小于 `64` 字节（默认值，可由 `list-max-ziplist-value` 配置），Redis 会使用**压缩列表**作为 List 类型的底层数据结构；
- 如果列表的元素不满足上面的条件，Redis 会使用**双向链表**作为 List 类型的底层数据结构；

**注意：在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表。**

#### 常用命令

```shell
# 将一个或多个值value插入到key列表的表头(最左边)，最后的值在最前面
LPUSH key value [value ...] 
# 将一个或多个值value插入到key列表的表尾(最右边)
RPUSH key value [value ...]
# 移除并返回key列表的头元素
LPOP key     
# 移除并返回key列表的尾元素
RPOP key 

# 返回列表key中指定区间内的元素，区间以偏移量start和stop指定，从0开始
LRANGE key start stop

# 从key列表表头弹出一个元素，没有就阻塞timeout秒，如果timeout=0则一直阻塞
BLPOP key [key ...] timeout
# 从key列表表尾弹出一个元素，没有就阻塞timeout秒，如果timeout=0则一直阻塞
BRPOP key [key ...] timeout
```

#### 应用场景

List的应用场景是**消息队列**。

消息队列在存取消息时，必须要满足三个需求，分别是**消息保序、处理重复的消息和保证消息可靠性**。List和Stream 两种数据类型，都可以满足消息队列的这三个需求。

- 消息保序：使用 LPUSH + RPOP；
- 阻塞读取：使用 BRPOP；
- 重复消息处理：生产者自行实现全局唯一 ID；
- 消息的可靠性：使用 BRPOPLPUSH

> 1. 如何满足消息保序需求？
>
> List 本身就是按先进先出的顺序对数据进行存取的，满足消息的顺序型，可以通过LPUSH + RPOP （或者反过来，RPUSH+LPOP）命令实现消息队列。
>
> > 不过由于List并不会主动通知消费者有新信息写入，消费者如果要及时处理消息，必须通过循环不断调用RPOP命令，会一直消耗CPU。
> >
> > 为了解决这个问题，Redis提供了 BRPOP 命令。**BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据**。
>
> 2. 如何处理重复消息？
>
> **生产者可以自行为每一个消息生成一个全部唯一ID**，消费者要记录已经处理过的消息的 ID。当获取到新消息时，首先判断该消息是否被处理。
>
> 3. 如何保证消息可靠性？
>
> 由于List不会留存被消费者读取后的消息，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。
>
> 为了留存消息，List 类型提供了 `BRPOPLPUSH` 命令，这个命令的**作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存**。

****

List作为消息队列的缺陷？

**List 不支持多个消费者消费同一条消息**，因为一旦消费者拉取一条消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费。 Redis 从 5.0 版本开始提供的 Stream 数据类型了，Stream 同样能够满足消息队列的三大需求，而且它还支持「消费组」形式的消息读取。

****

### Hash 

#### 介绍

Hash 是一个键值对（key - value）集合，其中 value 的形式如： `value=[{field1，value1}，...{fieldN，valueN}]`。Hash 特别适合用于存储对象。

#### 内部实现

Hash 类型的底层数据结构是由**压缩列表或哈希表**实现的：

- 如果哈希类型元素个数小于 `512` 个（默认值，可由 `hash-max-ziplist-entries` 配置），所有值小于 `64` 字节（默认值，可由 `hash-max-ziplist-value` 配置）的话，Redis 会使用**压缩列表**作为 Hash 类型的底层数据结构；
- 如果哈希类型元素不满足上面条件，Redis 会使用**哈希表**作为 Hash 类型的 底层数据结构。

**注意：在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。**

#### 常用命令

```shell
# 存储一个哈希表key的键值
HSET key field value   
# 获取哈希表key对应的field键值
HGET key field

# 在一个哈希表key中存储多个键值对
HMSET key field value [field value...] 
# 批量获取哈希表key中多个field键值
HMGET key field [field ...]       
# 删除哈希表key中的field键值
HDEL key field [field ...]    

# 返回哈希表key中field的数量
HLEN key       
# 返回哈希表key中所有的键值
HGETALL key 

# 为哈希表key中field键的值加上增量n
HINCRBY key field n  
```

#### 应用场景

Hash的应用场景有：**缓存对象和购物车**。

- **缓存对象**

Hash 类型的 （key，field， value） 的结构与对象的（对象id， 属性， 值）的结构相似，也可以用来存储对象。使用如下命令：

```shell
# 存储一个哈希表uid:1的键值
> HMSET uid:1 name Tom age 15
2
# 存储一个哈希表uid:2的键值
> HMSET uid:2 name Jerry age 13
2
# 获取哈希表用户id为1中所有的键值
> HGETALL uid:1
1) "name"
2) "Tom"
3) "age"
4) "15"
```

> 在介绍 String 类型的应用场景时有所介绍，String + Json也是存储对象的一种方式，那么存储对象时，到底用 String + json 还是用 Hash 呢？
>
> 一般对象用 String + Json 存储，对象中某些频繁变化的属性可以考虑抽出来用 Hash 类型存储。

- **购物车**

以用户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物车的3个要素。

> 涉及的命令如下：
>
> - 添加商品：`HSET cart:{用户id} {商品id} 1`
> - 添加数量：`HINCRBY cart:{用户id} {商品id} 1`
> - 商品总数：`HLEN cart:{用户id}`
> - 删除商品：`HDEL cart:{用户id} {商品id}`
> - 获取购物车所有商品：`HGETALL cart:{用户id}`
>
> 当前仅仅是将商品ID存储到了Redis 中，在回显商品具体信息的时候，还需要拿着商品 id 查询一次数据库，获取完整的商品的信息。

****

### Set

#### 介绍

Set 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。并且支持交集、并集、差集等操作。

#### 内部实现

Set 类型的底层数据结构是由**哈希表或整数集合**实现的：

- 如果集合中的元素都是整数且元素个数小于 `512` （默认值，`set-maxintset-entries`配置）个，Redis 会使用**整数集合**作为 Set 类型的底层数据结构；
- 如果集合中的元素不满足上面条件，则 Redis 使用**哈希表**作为 Set 类型的底层数据结构。

#### 常用命令

```shell
# 往集合key中存入元素，元素存在则忽略，若key不存在则新建
SADD key member [member ...]
# 从集合key中删除元素
SREM key member [member ...] 
# 获取集合key中所有元素
SMEMBERS key
# 获取集合key中的元素个数
SCARD key

# 判断member元素是否存在于集合key中
SISMEMBER key member

# 从集合key中随机选出count个元素，元素不从key中删除
SRANDMEMBER key [count]
# 从集合key中随机选出count个元素，元素从key中删除
SPOP key [count]

# 交集运算
SINTER key [key ...]
# 将交集结果存入新集合destination中
SINTERSTORE destination key [key ...]

# 并集运算
SUNION key [key ...]
# 将并集结果存入新集合destination中
SUNIONSTORE destination key [key ...]

# 差集运算
SDIFF key [key ...]
# 将差集结果存入新集合destination中
SDIFFSTORE destination key [key ...]
```

#### 应用场景

根据Set的特性，比较适合的场景是：**点赞、共同关注、抽奖等场景**。

> 注意：**Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞**。
>
> 在主从集群中，为了避免主库因为 Set 做聚合计算（交集、差集、并集）时导致主库被阻塞，我们可以选择一个从库完成聚合统计，或者把数据返回给客户端，由客户端来完成聚合统计。

- **点赞**

Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章id，value 是用户id。

```shell
# uid:1 、uid:2、uid:3 三个用户分别对 article:1 文章点赞了。
# uid:1 用户对文章 article:1 点赞
> SADD article:1 uid:1
(integer) 1
# uid:2 用户对文章 article:1 点赞
> SADD article:1 uid:2
(integer) 1
# uid:3 用户对文章 article:1 点赞
> SADD article:1 uid:3
(integer) 1

# uid:1 取消了对 article:1 文章点赞。
> SREM article:1 uid:1
(integer) 1

# 获取 article:1 文章所有点赞用户
> SMEMBERS article:1
1) "uid:3"
2) "uid:2"

# 获取 article:1 文章的点赞用户数量
> SCARD article:1
(integer) 2

# 判断用户 uid:1 是否对文章 article:1 点赞了
> SISMEMBER article:1 uid:1
(integer) 0  # 返回0说明没点赞，返回1则说明点赞了
```

- **共同关注**

Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。key 可以是用户id，value 则是已关注的公众号的id。

```shell
# uid:1 用户关注公众号 id 为 5、6、7、8、9
> SADD uid:1 5 6 7 8 9
(integer) 5
# uid:2  用户关注公众号 id 为 7、8、9、10、11
> SADD uid:2 7 8 9 10 11
(integer) 5

# uid:1 和 uid:2 共同关注的公众号
> SINTER uid:1 uid:2
1) "7"
2) "8"
3) "9"

# 给 uid:2 推荐 uid:1 关注的公众号
> SDIFF uid:1 uid:2
1) "5"
2) "6"

# 验证某个公众号是否同时被 uid:1 或 uid:2 关注
> SISMEMBER uid:1 5
(integer) 1 # 返回0，说明关注了
> SISMEMBER uid:2 5
(integer) 0 # 返回0，说明没关注
```

- **抽奖活动**

存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。key为抽奖活动名，value为员工名称。

```shell
# 把所有员工名称放入抽奖箱
>SADD lucky Tom Jerry John Sean Marry Lindy Sary Mark
(integer) 5

# 如果允许重复中奖，可以使用 SRANDMEMBER 命令。
# 抽取 1 个一等奖：
> SRANDMEMBER lucky 1
1) "Tom"
# 抽取 2 个二等奖：
> SRANDMEMBER lucky 2
1) "Mark"
2) "Jerry"

# 如果不允许重复中奖，可以使用 SPOP 命令
# 抽取一等奖1个
> SPOP lucky 1
1) "Sary"
# 抽取二等奖2个
> SPOP lucky 2
1) "Jerry"
2) "Mark"
```

****

### Zset

#### 介绍

Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序集合的元素值，一个是排序值。

有序集合保留了集合不能有重复成员的特性（分值可以重复），但不同的是，有序集合中的元素可以排序。

#### 内部实现

Zset 类型的底层数据结构是由**压缩列表或跳表**实现的：

- 如果有序集合的元素个数小于 `128` 个，并且每个元素的值小于 `64` 字节时，Redis 会使用**压缩列表**作为 Zset 类型的底层数据结构；
- 如果有序集合的元素不满足上面的条件，Redis 会使用**跳表**作为 Zset 类型的底层数据结构；

> 注意：在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。

#### 常用命令

```shell
# 往有序集合key中加入带分值元素
ZADD key score member [[score member]...]   
# 往有序集合key中删除元素
ZREM key member [member...]                 
# 返回有序集合key中元素member的分值
ZSCORE key member
# 返回有序集合key中元素个数
ZCARD key 

# 为有序集合key中元素member的分值加上increment
ZINCRBY key increment member 

# 正序获取有序集合key从start下标到stop下标的元素
ZRANGE key start stop [WITHSCORES]
# 倒序获取有序集合key从start下标到stop下标的元素
ZREVRANGE key start stop [WITHSCORES]

# 返回有序集合中指定分数区间内的成员，分数由低到高排序。
ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]

# 返回指定成员区间内的成员，按字典正序排列, 分数必须相同。
ZRANGEBYLEX key min max [LIMIT offset count]
# 返回指定成员区间内的成员，按字典倒序排列, 分数必须相同
ZREVRANGEBYLEX key max min [LIMIT offset count]

# Zset 运算操作（相比于 Set 类型，ZSet 类型没有支持差集运算）
# 并集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积
ZUNIONSTORE destkey numberkeys key [key...] 
# 交集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积
ZINTERSTORE destkey numberkeys key [key...]
```

#### 应用场景

Zset 类型（Sorted Set，有序集合） 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。在面对需要展示最新列表、排行榜等场景时，**如果数据更新频繁或者需要分页显示**，可以优先考虑使用 Sorted Set。

- **排行榜**

有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。

我们以博文点赞排名为例

```shell
# 小林发表了五篇博文，分别获得赞为 200、40、100、50、150
# arcticle:1 文章获得了200个赞
> ZADD user:xiaolin:ranking 200 arcticle:1
(integer) 1
# arcticle:2 文章获得了40个赞
> ZADD user:xiaolin:ranking 40 arcticle:2
(integer) 1
# arcticle:3 文章获得了100个赞
> ZADD user:xiaolin:ranking 100 arcticle:3
(integer) 1
# arcticle:4 文章获得了50个赞
> ZADD user:xiaolin:ranking 50 arcticle:4
(integer) 1
# arcticle:5 文章获得了150个赞
> ZADD user:xiaolin:ranking 150 arcticle:5
(integer) 1

# 文章 arcticle:4 新增一个赞，可以使用 ZINCRBY 命令（为有序集合key中元素member的分值加上increment）
> ZINCRBY user:xiaolin:ranking 1 arcticle:4
"51"

# 查看某篇文章的赞数，可以使用 ZSCORE 命令（返回有序集合key中元素个数）
> ZSCORE user:xiaolin:ranking arcticle:4
"50"

# 获取小林文章赞数最多的 3 篇文章，可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）
# WITHSCORES 表示把 score 也显示出来
> ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES
1) "arcticle:1"
2) "200"
3) "arcticle:5"
4) "150"
5) "arcticle:3"
6) "100"

# 获取小林 100 赞到 200 赞的文章，可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员，分数由低到高排序）
> ZRANGEBYSCORE user:xiaolin:ranking 100 200 WITHSCORES
1) "arcticle:3"
2) "100"
3) "arcticle:5"
4) "150"
5) "arcticle:1"
6) "200"
```

- **电话、姓名排序**

使用有序集合的 `ZRANGEBYLEX` 或 `ZREVRANGEBYLEX` 可以帮助我们实现电话号码或姓名的排序，我们以 `ZRANGEBYLEX` （返回指定成员区间内的成员，按 key 正序排列，分数必须相同）为例。

> **注意：不要在分数不一致的 SortSet 集合中去使用 ZRANGEBYLEX和 ZREVRANGEBYLEX 指令，因为获取的结果会不准确。**

电话排序

```shell
# 可以将电话号码存储到 SortSet 中，然后根据需要来获取号段
> ZADD phone 0 13100111100 0 13110114300 0 13132110901 
(integer) 3
> ZADD phone 0 13200111100 0 13210414300 0 13252110901 
(integer) 3
> ZADD phone 0 13300111100 0 13310414300 0 13352110901 
(integer) 3

# 获取所有号码
> ZRANGEBYLEX phone - +
1) "13100111100"
2) "13110114300"
3) "13132110901"
4) "13200111100"
5) "13210414300"
6) "13252110901"
7) "13300111100"
8) "13310414300"
9) "13352110901"

# 获取 132 号段的号码
> ZRANGEBYLEX phone [132 (133
1) "13200111100"
2) "13210414300"
3) "13252110901"

# 获取132、133号段的号码
> ZRANGEBYLEX phone [132 (134
1) "13200111100"
2) "13210414300"
3) "13252110901"
4) "13300111100"
5) "13310414300"
6) "13352110901"
```

姓名排序

```shell
> zadd names 0 Toumas 0 Jake 0 Bluetuo 0 Gaodeng 0 Aimini 0 Aidehua 
(integer) 6

# 获取所有人的名字
> ZRANGEBYLEX names - +
1) "Aidehua"
2) "Aimini"
3) "Bluetuo"
4) "Gaodeng"
5) "Jake"
6) "Toumas"

# 获取名字中大写字母A开头的所有人
> ZRANGEBYLEX names [A (B
1) "Aidehua"
2) "Aimini"

# 获取名字中大写字母 C 到 Z 的所有人
> ZRANGEBYLEX names [C [Z
1) "Gaodeng"
2) "Jake"
3) "Toumas"
```

****

### BitMap

#### 介绍

Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行`0|1`的设置，表示某个元素的值或者状态，时间复杂度为O(1)。

由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用**二值统计的场景**。

#### 内部实现

Bitmap 本身是**用 String 类型作为底层数据结构实现**的一种统计二值状态的数据类型。

String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组。

#### 常用命令

```shell
# 设置值，其中value只能是 0 和 1
SETBIT key offset value

# 获取值
GETBIT key offset

# 获取指定范围内值为 1 的个数
# start 和 end 以字节为单位
BITCOUNT key start end

# BitMap间的运算
# operations 位移操作符，枚举值
  AND 与运算 &
  OR 或运算 |
  XOR 异或 ^
  NOT 取反 ~
# result 计算的结果，会存储在该key中
# key1 … keyn 参与运算的key，可以有多个，空格分割，not运算只能一个key
# 当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0。
# 返回值是保存到 destkey 的字符串的长度（以字节byte为单位），和输入 key 中最长的字符串长度相等。
BITOP [operations] [result] [key1] [keyn…]

# 返回指定key中第一次出现指定value(0/1)的位置
BITPOS [key] [value]
```

#### 应用场景

Bitmap 类型非常适合二值状态统计的场景，这里的二值状态就是指集合元素的取值就只有 0 和 1 两种，在记录海量数据时，Bitmap 能够有效地节省内存空间。常用场景有：**签到统计、判断用户登录状态、连续签到用户数**。

- **签到统计**

在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。

签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。

假设我们要统计 ID 100 的用户在 2022 年 6 月份的签到情况，就可以按照下面的步骤进行操作。

```shell
# 执行下面的命令，记录该用户 6 月 3 号已签到
SETBIT uid:sign:100:202206 2 1

# 检查该用户 6 月 3 日是否签到
GETBIT uid:sign:100:202206 2 

# 统计该用户在 6 月份的签到次数
BITCOUNT uid:sign:100:202206

# 统计这个月首次打卡时间
# 需要注意的是，因为 offset 从 0 开始的，所以我们需要将返回的 value + 1 。
BITPOS uid:sign:100:202206 1
```

- **判断用户登录状态**

Bitmap 提供了 `GETBIT、SETBIT` 操作，通过一个偏移值 offset 对 bit 数组的 offset 位置的 bit 位进行读写操作，需要注意的是 offset 从 0 开始。

只需要一个 key = login_status 表示存储用户登陆状态集合数据， 将用户 ID 作为 offset，在线就设置为 1，下线设置 0。通过 `GETBIT`判断对应的用户是否在线。 5000 万用户只需要 6 MB 的空间。

```shell
# 假如我们要判断 ID = 10086 的用户的登陆情况
# 执行以下指令，表示用户已登录
SETBIT login_status 10086 1

# 检查该用户是否登陆，返回值 1 表示已登录
GETBIT login_status 10086

# 登出，将 offset 对应的 value 设置成 0
SETBIT login_status 10086 0
```

- **连续签到用户总数**

如何统计出这连续 7 天连续打卡用户总数呢？

我们把每天的日期作为 Bitmap 的 key，userId 作为 offset，若是打卡则将 offset 位置的 bit 设置成 1。key 对应的集合的每个 bit 位的数据则是一个用户在该日期的打卡记录。

一共有 7 个这样的 Bitmap，如果我们能对这 7 个 Bitmap 的对应的 bit 位做 『与』运算。同样的 UserID offset 都是一样的，当一个 userID 在 7 个 Bitmap 对应对应的 offset 位置的 bit = 1 就说明该用户 7 天连续打卡。

结果保存到一个新 Bitmap 中，我们再通过 `BITCOUNT` 统计 bit = 1 的个数便得到了连续打卡 7 天的用户总数了。

```shell
# 假设要统计 3 天连续打卡的用户数，则是将三个 bitmap 进行 AND 操作，
# 并将结果保存到 destmap 中，接着对 destmap 执行 BITCOUNT 统计

# 与操作
BITOP AND destmap bitmap:01 bitmap:02 bitmap:03
# 统计 bit 位 =  1 的个数
BITCOUNT destmap
```

****

### HyperLogLog

#### 介绍

Redis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型，是一种用于「统计基数」的数据集合类型，**基数统计就是指统计一个集合中不重复的元素个数。** 但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。简单来说 HyperLogLog **提供不精确的去重计数**。

> HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。

#### 内部实现

HyperLogLog 的实现涉及到很多数学问题，可以看看看看这个：[HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog)。

#### 常用命令

HyperLogLog 命令很少，就三个。

```shell
# 添加指定元素到 HyperLogLog 中
PFADD key element [element ...]

# 返回给定 HyperLogLog 的基数估算值。
PFCOUNT key [key ...]

# 将多个 HyperLogLog 合并为一个 HyperLogLog
PFMERGE destkey sourcekey [sourcekey ...]
```

#### 应用场景

- **百万级网页UV计数**

Redis HyperLogLog 优势在于只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数，所以，非常适合统计百万级以上的网页 UV 的场景。

> UV(Unique visitor)指访问某个站点或点击某个网页的不同IP地址的人数

```shell
# 在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中PFADD 
page1:uv user1 user2 user3 user4 user5

# 用 PFCOUNT 命令直接获得 page1 的 UV 值
PFCOUNT page1:uv
```

****

### GEO

#### 介绍

Redis GEO 是 Redis 3.2 版本新增的数据类型，**主要用于存储地理位置信息，并对存储的信息进行操作。**

在日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中。

#### 内部实现

GEO 本身并没有设计新的底层数据结构，而是**直接使用了 Sorted Set 集合类型**。

GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。

这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。

#### 常用命令

```shell
# 存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。
GEOADD key longitude latitude member [longitude latitude member ...]

# 从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。
GEOPOS key member [member ...]

# 返回两个给定位置之间的距离。
GEODIST key member1 member2 [m|km|ft|mi]

# 根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]
```

#### 应用场景

- **滴滴叫车**

以滴滴叫车的场景为例，介绍下具体如何使用 GEO 命令：GEOADD 和 GEORADIUS 这两个命令。

假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。

```shell
# 执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中
GEOADD cars:locations 116.034579 39.030452 33
```

当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。

例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。

```shell
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10
```

****

### Stream

#### 介绍

Redis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。

Stream 类型，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。

****

****

## Redis的数据结构

### 键值对如何实现？

Redis的键值对中key就是字符串对象，而 **value 可以是字符串对象，也可以是集合数据类型的对象**，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。

Redis 是使用了一个「哈希表」保存所有键值对，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。哈希桶存放的是指向键值对数据的指针，即指向的是**Redis对象**，Redis 中的每个对象都由 redisObject 结构表示。

对象结构里包含的成员变量：

- type，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对象、Set 对象和 Zset 对象）；
- encoding，标识该对象使用了哪种底层的数据结构；
- **ptr，指向底层数据结构的指针**。

****

### SDS

Redis 是用 C 语言实现的，但是它没有直接使用 C 语言的 char* 字符数组来实现字符串，而是自己封装了一个名为简单动态字符串（simple dynamic string，SDS） 的数据结构来表示字符串。

> C语言字符串的缺陷
>
> - 获取字符串长度的时间复杂度为 O（N）；
> - 字符串的结尾是以 “\0” 字符标识，字符串里面不能包含有 “\0” 字符，因此不能保存二进制数据；
> - 字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；

SDS的结构定义如下：

![image-20230221144543165](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230221144543165.png)

> - **len，记录了字符串长度**。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。
> - **alloc，分配给字符数组的空间长度**。这样在修改字符串的时候，可以通过 `alloc - len` 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。
> - **flags，用来表示不同类型的 SDS**。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。
> - **buf[]，字符数组，用来保存实际数据**。不仅可以保存字符串，也可以保存二进制数据。

SDS的优势如下：

- **O(1)复杂度获取字符串长度**

- **二进制安全**

 SDS 不需要用 “\0” 字符来标识字符串结尾了，而是**有个专门的 len 成员变量来记录长度，所以可存储包含 “\0” 的数据**。但是 SDS 为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\0” 字符。因此，SDS 的 API 都是以处理二进制的方式来处理 SDS 存放在 buf[] 里的数据。

- **不会出现缓冲区溢出**

Redis 的 SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过 `alloc - len` 计算，可以算出剩余可用的空间大小，**当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小**。

> 扩容规则
>
> - 如果所需的 sds 长度**小于 1 MB**，那么最后的扩容是按照**翻倍扩容**来执行的，即 2 倍的newlen
> - 如果所需的 sds 长度**超过 1 MB**，那么最后的扩容长度应该是 newlen **+ 1MB**。
>
> 通过扩容机制，**有效的减少了内存分配次数。**

- **节省内存空间**

Redis 一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。这 5 种类型的主要**区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同，目的是为了能灵活保存不同大小的字符串，从而有效节省内存空间**。

Redis 在编程上还**使用了专门的编译优化来节省内存空间**，即在 struct 声明了 `__attribute__ ((packed))` ，它的作用是：**告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐**。

```c
#include <stdio.h>

struct __attribute__((packed)) test2  {
    char a;
    int b;
 } test2;
 
int main() {
     printf("%lu\n", sizeof(test2));
     return 0;
}
```

****

### 链表

Redis底层实现的链表是**双向链表**。

- **链表节点结构设计**

「链表节点」结构如下：

```c
typedef struct listNode {
  
    //前置节点
    struct listNode *prev;
  
    //后置节点
    struct listNode *next;
  
    //节点的值
    void *value;
} listNode;
```

- **链表结构设计**

Redis 在 listNode 结构体基础上又封装了 list 这个数据结构，这样操作起来会更方便，链表结构如下：

```c
typedef struct list {
    //链表头节点
    listNode *head;
    //链表尾节点
    listNode *tail;
    //节点值复制函数
    void *(*dup)(void *ptr);
    //节点值释放函数
    void (*free)(void *ptr);
    //节点值比较函数
    int (*match)(void *ptr, void *key);
    //链表节点数量
    unsigned long len;
} list;
```

> Redis链表优点：
>
> - listNode 链表节点的结构里带有 prev 和 next 指针，**获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表**；
> - list 结构因为提供了表头指针 head 和表尾节点 tail，所以**获取链表的表头节点和表尾节点的时间复杂度只需O(1)**；
> - list 结构因为提供了链表节点数量 len，所以**获取链表中的节点数量的时间复杂度只需O(1)**；
> - listNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此**链表节点可以保存各种不同类型的值**；
>
> ****
>
> 缺陷如下：
>
> - 链表每个节点之间的内存都是不连续的，意味着**无法很好利用 CPU 缓存**。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。
> - 还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，**内存开销较大**。

### 压缩列表

压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。

#### 压缩列表结构设计

![image-20230221151135754](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230221151135754.png)

压缩列表在表头有三个字段：

- ***zlbytes***，记录整个压缩列表占用对内存字节数；
- ***zltail***，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；
- ***zllen***，记录压缩列表包含的节点数量；
- ***zlend***，标记压缩列表的结束点，固定值 0xFF（十进制255）。

并且压缩列表节点包含三部分内容：

- ***prevlen***，记录了「前一个节点」的长度，目的是为了实现从后向前遍历；
- ***encoding***，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。
- ***data***，记录了当前节点的实际数据，类型和长度都由 `encoding` 决定；

>  prevlen 属性的空间大小跟前一个节点长度值有关，比如：
>
>  如果**前一个节点的长度小于 254 字节**，那么 prevlen 属性需要用 **1 字节的空间**来保存这个长度值；
>
>  如果**前一个节点的长度大于等于 254 字节**，那么 prevlen 属性需要用 **5 字节的空间**来保存这个长度值；

****

#### 连锁更新

压缩列表存在**连锁更新**的问题，压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。**而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降**。

****

#### 压缩列表的缺陷

- 要查找定位第一个元素和最后一个元素，可以通过表头三个字段（zllen）的长度直接定位，复杂度是 O(1)。而**查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素**。
- 存在连锁更新问题。

****

### 哈希表

#### 哈希表结构设计

哈希表是一个数组（dictEntry **table），数组的每个元素是一个指向「哈希表节点（dictEntry）」的指针。哈希表节点结构里不仅包含指向键和值的指针，还包含了指向下一个哈希表节点的指针，用于解决哈希冲突。

```c
// 哈希表结构
typedef struct dictht {
    //哈希表数组
    dictEntry **table;
    //哈希表大小
    unsigned long size;  
    //哈希表大小掩码，用于计算索引值
    unsigned long sizemask;
    //该哈希表已有的节点数量
    unsigned long used;
} dictht;

// 哈希表节点结构
typedef struct dictEntry {
    //键值对中的键
    void *key;
  
    //键值对中的值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    //指向下一个哈希表节点，形成链表
    struct dictEntry *next;
} dictEntry;
```

****

#### 哈希冲突

当有两个以上数量的 kay 被分配到了哈希表中同一个哈希桶上时，此时称这些 key 发生了冲突。Redis 采用了「**链式哈希**」的方法来解决哈希冲突。

实现的方式就是每个哈希表节点都有一个 next 指针，用于指向下一个哈希表节点，因此多个哈希表节点可以用 next 指针构成一个单项链表，**被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来**，这样就解决了哈希冲突。

****

#### 渐进式rehash

Redis一个哈希表中定义了两个哈希数组的结构，用于rehash时使用。为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了**渐进式 rehash**，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。

渐进式rehash步骤：

- 给「哈希表 2」 分配空间；
- **在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上**；
- 随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。

在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。新增一个key-value时，则会被保存到「哈希表2」中。

****

#### rehash触发条件

触发 rehash 操作的条件，主要有两个：

- **当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。**
- **当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。**

****

****

### 整数集合

#### 整数集合结构设计

整数集合本质上是一块连续内存空间，它的结构定义如下：

```c
typedef struct intset {
  
    //编码方式
    uint32_t encoding;
  
    //集合包含的元素数量
    uint32_t length;
  
    //保存元素的数组
    int8_t contents[];
} intset;
```

保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t 类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值。

#### 升级操作

整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果**新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级**，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性。

整数集合升级的过程不会重新分配一个新类型的数组，而是在原本的数组上扩展空间，然后在将每个元素按间隔类型大小分割。

> 升级的好处？
>
> 如果要让一个数组同时保存 int16_t、int32_t、int64_t 类型的元素，最简单做法就是直接使用 int64_t 类型的数组。不过这样的话，当如果元素都是 int16_t 类型的，就会造成内存浪费的情况。因此，整数集合升级的好处是**节省内存资源**。
>
> **注意：整数集合不支持降级操作。**

****

### 跳表

Redis 只有 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。

zset 结构体里有两个数据结构：一个是跳表，一个是哈希表。这样的好处是既能进行高效的范围查询，也能进行高效单点查询。

#### 跳表结构设计

**跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表**，这样的好处是能快读定位数据。

数据结构定义如下：

```c
typedef struct zskiplistNode {
    //Zset 对象的元素值
    sds ele;
    //元素权重值
    double score;
    //后向指针
    struct zskiplistNode *backward;
  
    //节点的level数组，保存每层上的前向指针和跨度
    struct zskiplistLevel {
        struct zskiplistNode *forward;
        unsigned long span;
    } level[];
} zskiplistNode;
```

- 每个跳表节点都有一个后向指针（struct zskiplistNode *backward），指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。

- level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。

![image-20230221183548719](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230221183548719.png)

> **跨度实际上是为了计算这个节点在跳表中的排位**。从头节点到该结点的查询路径上，将沿途访问过的所有层的跨度累加起来，得到的结果就是目标节点在跳表中的排位。

#### 跳表节点查询过程

查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，

- 当前节点的权重「小于」要查找的权重时；或者当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时；跳表会访问该层的下一个节点。
- 如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针。

#### 跳表节点层数设置

跳表的相邻两层的节点数量的比例会影响跳表的查询性能。**最理想的比例是 2:1，查找复杂度可以降低到 O(logN)**。

但如果在增加或删除节点是，来调整以维持这个比例将会增加额外的开销。

Redis 则采用一种巧妙的方法是，**跳表在创建节点的时候，随机生成每个节点的层数**，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。

> 具体的做法是，**跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数**。这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。
>
> **注意：头节点也是跳表节点，因此在创建跳表「头节点」的时候，就会直接创建 64 层高的头节点。**

****

#### 为什么用跳表不用平衡树？

为什么 Zset 的实现用跳表而不用平衡树（如 AVL树、红黑树等）？

- **在做范围查找的时候，跳表比平衡树操作要简单**。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。
- **从算法实现难度上来比较，跳表比平衡树要简单得多**。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。

****

### quicklist

在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。其实 quicklist 就是「**双向链表 + 压缩列表**」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。

为了解决压缩列表的问题，quicklist 解决办法，**通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。**

![image-20230221180719024](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230221180719024.png)

在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是**会检查插入位置的压缩列表是否能容纳该元素**，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。

****

### listpack

quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表。

**listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题**。

> 压缩列表的entry为什么要保存prevlen呢？listpack改成len之后不会影响功能吗？
>
> 压缩列表的 entry 保存 prevlen 是为了实现节点从后往前遍历，知道前一个节点的长度，就可以计算前一个节点的偏移量。
>
> listpack 一样可以支持从后往前遍历的。详细的算法可以看Redis中[lpDecodeBacklen函数](https://github.com/antirez/listpack/blob/master/listpack.c)源码，lpDecodeBacklen 函数就可以从当前列表项起始位置的指针开始，向左逐个字节解析，得到前一项的 entry-len 值。
>
> > 具体的原理在于entry-len值的特殊设计，**与protobuf中的varInts压缩int类型数值原理一样。**
> >
> > entry-len的**每一个字节的最高位不记录具体数值，而用于记录是否为最后一个字节。** 即最高位为1，表示entry-len还没有结束。

![image-20230221181132328](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230221181132328.png)

****

****

## Redis线程模型

### Redis是单线程吗？

**Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的**，但是，**Redis 程序并不是单线程的**，Redis 在启动的时候，是会**启动后台线程**（BIO）：

- **Redis 在 2.6 版本**，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务
- **Redis 在 4.0 版本之后**，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。

****

### Redis单线程模式是怎样的？

Redis的网络 I/O 和命令处理都是单线程，由主线程处理。

当Redis初始化完成后，主线程会进入到一个**事件循环函数**，主要会做以下事情：

> - 首先，先调用**处理发送队列函数**，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。
> - 接着，调用 epoll_wait 函数等待事件的到来：
>     - 如果是**连接事件**到来，则会调用**连接事件处理函数**，该函数会做这些事情：调用 accpet 获取已连接的 socket -> 调用 epoll_ctl 将已连接的 socket 加入到 epoll -> 注册「读事件」处理函数；
>     - 如果是**读事件**到来，则会调用**读事件处理函数**，该函数会做这些事情：调用 read 获取客户端发送的数据 -> 解析命令 -> 处理命令 -> 将客户端对象添加到发送队列 -> 将执行结果写到发送缓存区等待发送；
>     - 如果是**写事件**到来，则会调用**写事件处理函数**，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。

![image-20230221190943838](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230221190943838.png)

****

### Redis用单线程为什么还这么快？

Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：

- Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构，因此 **Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU**，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；
- Redis 采用单线程模型可以**避免了多线程之间的竞争**，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
- Redis 采用了 **I/O 多路复用机制**处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

****

### Redis6.0之前使用单线程，之后为什么引入多线程？

- **采用单线程原因**

**CPU 并不是制约 Redis 性能表现的瓶颈所在**，更多情况下是受到内存大小和网络I/O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题。如果你想要使用服务的多核CPU，可以在一台服务器上启动多个节点或者采用分片集群的方式。

使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，**增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗**。

- **Redis6.0为什么引入多线程？**

在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，**这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上**。所以为了提高网络 I/O 的并行度，**Redis 6.0 对于网络 I/O 采用多线程来处理。但是对于命令的执行，Redis 仍然使用单线程来处理，** 所以大家不要误解Redis 有多线程同时执行命令。

> 因此， Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会**额外创建 6 个线程**（*这里的线程数不包括主线程*）：
>
> 1. Redis-server ： Redis的主线程，主要负责执行命令；
>
> 2. bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；
>
> 3. io_thd_1、io_thd_2、io_thd_3：三个 I/O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I/O 多线程，用来分担 Redis 网络 I/O 的压力。

****

****

## Redis持久化

### Redis如何实现数据不丢失？

Redis 的读写操作都是在内存中，所以 Redis 性能才会高，但是当 Redis 重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制。

Redis 共有三种数据持久化的方式：

- **AOF 日志**：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；
- **RDB 快照**：将某一时刻的内存数据，以二进制的方式写入磁盘；
- **混合持久化方式**：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；

****

### AOF日志持久化

保存写操作命令到日志的持久化方式，就是 Redis 里的 **AOF(Append Only File)** 持久化功能，

> **注意只会记录写操作命令，读操作命令是不会被记录的**, 在 Redis 中 AOF 持久化功能默认是不开启的。

Redis是先执行写操作命令，后才将该命令记录到 AOF 日志里的。这样有两个好处：

- **避免额外的检查开销。** 如果先写入AOF日志，那么在写入前必须进行语法检查。
- **不会阻塞当前写操作命令的执行**，因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。

> AOF持久化功能的风险
>
> 第一个风险是，因为执行写操作和记录日志是来个过程，就**有可能出现数据丢失**的风险。
>
> 第二个风险是，会阻塞「下一个」命令。

****

#### 三种回写策略

Redis执行成功写操作命令后，会将命令追加到`server.aof_buf`缓存区中，然后通过 write() 系统调用，将 aof_buf 缓冲区的数据拷贝到内核缓冲区Page Cache中。Redis 提供了 3 种写回硬盘的策略，控制将Page Cache（内核缓冲区）的数据写入磁盘。

- **Always**，每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；**本质就是每次调用write()系统调用后，就执行 fsync() 函数进行刷盘**。
- **Everysec**，每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；**即创建一个异步函数调用fsync()函数**。
- **No**，不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机。

****

#### AOF重写机制

AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。文件过大就会带来性能问题。Redis 为了避免 AOF 文件越写越大，提供了 **AOF 重写机制**。AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后**将每一个键值对用一条命令记录**到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。

> 不直接复用现有的 AOF 文件，而是先写到新的 AOF 文件再覆盖过去。目的是为了防止**如果AOF重写过程失败了，现有的 AOF 文件就会造成污染**，可能无法用于恢复使用。

****

#### AOF后台重写

Redis 的**重写 AOF 过程是由后台子进程 \*bgrewriteaof\* 来完成的**，这么做可以达到两个好处：

- 子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；
- **子进程带有主进程的数据副本**，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而**当父子进程任意一方修改了该共享内存，就会发生「写时复制」**，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。

> 1. 子进程是怎么拥有主进程一样的数据副本的呢？
>
> 主进程在通过 `fork` 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「**页表**」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存。这样一来，子进程就共享了父进程的物理内存数据了，这样能够**节约物理内存资源**，页表对应的页表项的属性会标记该物理内存的权限为**只读**。
>
> 当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发**写保护中断**，然后操作系统会在「写保护中断处理函数」里进行**物理内存的复制（注意：只会复制修改的物理内存）**，并重新设置其内存映射关系，将父子进程的内存读写权限设置为**可读写**，最后才会对内存进行写操作，这个过程被称为「**写时复制(Copy On Write)**」。即**在发生写操作的时候，操作系统才会去复制物理内存**。这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。
>
> > 有两个阶段会导致阻塞父进程：
> >
> > - 创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
> > - 创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；
>
> ****
>
> 2. 重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，导致数据不一致，怎么办？
>
> 为了解决这种数据不一致问题，Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。
>
> 当子进程完成 AOF 重写工作后，会向主进程发送一条信号，主进程收到信号后会调用信号处理函数完成如下工作：
>
> - 将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；
> - 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。

****

### RDB快照持久化

RDB 文件的内容是二进制数据。RDB快照就是记录某一个瞬间的内存数据，记录的是实际数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以。

#### 快照如何用？

Redis 提供了两个命令来生成 RDB 文件，分别是 `save` 和 `bgsave`，他们的区别就在于是否在「主线程」里执行：

- 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；
- 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以**避免主线程的阻塞**；

> 注意：RDB 文件的加载工作是在服务器启动时自动执行的，Redis 并没有提供专门用于加载 RDB 文件的命令。

RDB快照的缺陷：

因为Redis 的快照是**全量快照**，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少。

****

#### 执行快照时，数据能被修改吗？

执行 bgsave 过程中，Redis 依然**可以继续处理操作命令**的，也就是数据是能被修改的。用到的技术就是**写时复制技术**。

> 执行bgsave命令的时候，主进程会通过`fork()`创建子进程，并且会复制父进程的页表，此时父子进程的页表指向同一块物理内存。
>
> 当父进程要修改某一块数据时，就会发生写时复制，然后父进程在这一块数据副本上进行修改。

因此，Redis 在使用 bgsave 快照过程中，如果主线程修改了内存数据，不管是否是共享的内存数据，RDB 快照都无法写入主线程刚修改的数据。

****

### Redis大key对持久化有什么影响？

#### 大key对AOF日志的影响

AOF日志有三种写回磁盘的策略，分别是：**Always、Everysec、No**。

在使用Always写回磁盘策略时，每次主线程在执行完命令后，会把数据写入到 AOF 日志文件，然后会调用 fsync() 函数，将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。**如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的**。

另外两种策略下，持久化大key不会对主线程造成影响。

****

#### 大key堆AOF重写和RDB的影响

AOF重写机制和RDB快照(bgsave)，都会调用`fork()`创建子进程完成。

- 随着 Redis 存入越来越多的大 Key，那么 Redis 就会占用很多内存，对应的页表就会越大。在通过 `fork()` 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是**内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象**。
- 如果创建完子进程后，**父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞**。

> 大 key 除了会影响持久化之外，还会有以下的影响:
>
> - **客户端超时阻塞。** 由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
>
> - **引发网络阻塞。** 每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
>
> - **阻塞工作线程。** 如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
>
> - **内存分布不均。** 集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。
>
> ****
>
> 如何避免大 Key 呢？
>
> 最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是**用 unlink 命令**（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。

****

### 为什么会有混合持久化？

RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。

AOF 优点是丢失数据少，但是数据恢复不快。

Redis 4.0 提出了**混合使用 AOF 日志和内存快照**，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。

> 混合持久化工作在 **AOF 日志重写过程**，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，此过程中主线程的操作命令会被记录到重写缓冲区里面，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件。因此，AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。

**混合持久化优点：**

- 混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。

**混合持久化缺点：**

- AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；
- 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。

****

## Redis高可用

### 主从复制

Redis提供了**主从复制模式**，来保证多台服务器的数据一致性，且主从服务器之间采用的是「读写分离」的方式。即主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。

> 实际中，为了防止过多的从服务器导致主服务器**生成 RDB 和传输 RDB 的压力**过大，会**分摊主服务器的压力**，即并不是所有的从服务器都通过主服务器同步数据，而是一些从服务器会与另外的从服务器相连来同步数据。

主从复制共有三种模式：**全量复制、基于长连接的命令传播、增量复制**。

#### 第一次同步

使用 `replicaof`（Redis 5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系。

> 例如，有A、B两个服务器，在B服务器上执行命令`replicaof <服务器 A 的 IP 地址> <服务器 A 的 Redis 端口号>`，接着服务器B就会服务器A的从服务器。

第一次同步的过程可以分为三个阶段：

- 第一阶段是建立链接、协商同步；
- 第二阶段是主服务器同步数据给从服务器；
- 第三阶段是主服务器发送新写操作命令给从服务器。

> ![image-20230222085652749](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230222085652749.png)
>
> **第一阶段：建立连接、协商同步**
>
> 执行了 replicaof 命令后，从服务器就会给主服务器发送 `psync` 命令，表示要进行数据同步。该命令包含两个参数，分别是**主服务器的 runID** 和**复制进度 offset**。
>
> - runID，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 "?"。
> - offset，表示复制的进度，第一次同步时，其值为 -1。
>
> 主服务器收到命令后，会用 `FULLRESYNC` 作为响应命令返回给对方。这个响应表明将采用**全量复制**的方式。
>
> ****
>
> **第二阶段：主服务器同步数据给从服务器**
>
> 主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器。从服务器收到 RDB 文件后，丢弃所有旧数据，将 RDB 数据载入到内存。在此过程中，主服务器接收到的写命令，**将写入到replication buffer缓冲区中**。
>
> ****
>
> **第三阶段：主服务器发送新的写操作命令给从服务器**
>
> 从服务器完成 RDB 的载入后，会回复一个确认消息给主服务器。主服务器将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，从服务器执行来自主服务器 replication buffer 缓冲区里发来的命令，这时主从服务器的数据就一致了。

****

#### 命令传播

主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。后续主从服务器将通过这个**长连接**保持数据的一致性。主服务器可以通过这个连接继续**将写操作命令传播给从服务器**，然后从服务器执行该命令，使得与主服务器的数据库状态相同。

****

#### 增量复制

主从服务器会通过命令传播的方式保持数据一致性，但如果网络断开连接后从服务器又连接上了主服务器，此时如何保证数据一致性呢？

网络断开又恢复后，从主从服务器会采用**增量复制**的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。此时主要有三个步骤：

- 从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；
- 主服务器收到该命令后，然后**用 CONTINUE 响应命令**告诉从服务器接下来采用增量复制的方式同步数据；
- 然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。

> 主服务器如何判断哪些是增量数据？
>
> 主要是通过**repl_backlog_buffer**是一个「**环形**」缓冲区，用于主从服务器断连后，从中找到差异的数据；主服务器写偏移量`master_repl_offset`和从服务器的读偏移量`slave_repl_offset`来实现。
>
> > 具体流程：
> >
> > 主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里。从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：
> >
> > - 如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**增量同步**的方式；
> > - 相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**全量同步**的方式。
> >
> > 找到增量数据后，会将增量的数据写入到 replication buffer 缓冲区，然后传播给从服务器。
> >
> > ![image-20230222092456741](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230222092456741.png)

****

#### 怎么判断Redis某个节点是否正常工作？

Redis 判断节点是否正常工作，基本都是通过互相的 ping-pong 心跳检测机制。Redis 主从节点发送的心态间隔是不一样的，而且作用也有一点区别：

- Redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态。
- Redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了：
    - 实时监测主从节点网络状态；
    - 上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。

****

#### 主从复制架构中，过期key如何处理？

主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。

****

#### Redis是同步复制还是异步复制？

Redis 主节点每次收到写命令之后，**先写到内部的缓冲区，然后异步发送给从节点**。

****

#### 主从复制中两个buffer(replication buffer 与repl backlog buffer)有什么区别？

- 出现的阶段不一样：
    - repl backlog buffer 是在增量复制阶段出现，**一个主节点只分配一个 repl backlog buffer**；
    - replication buffer 是在全量复制阶段和增量复制阶段都会出现，**主节点会给每个新连接的从节点，分配一个 replication buffer**；
- 这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：
    - 当 repl backlog buffer 满了，因为是环形结构，会直接**覆盖起始位置数据**;
    - 当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，**重新开始全量复制**。

****

#### 如何应对主从数据不一致？

主从数据不一致，是**因为主从节点间的命令复制是异步进行的**，所以无法实现强一致性保证（主从数据时时刻刻保持一致）。

> 可以通过如下思路：
>
> 第一种方法，尽量保证主从节点间的网络连接状况良好，避免主从节点在不同的机房。
>
> 第二种方法，开发一个外部程序来监控主从节点间的复制进度。通过`master_repl_offset`与`slave_repl_offset`两个偏移量计算出主从节点复制进度差值，当差值大于一个阈值时，让客户端不再和这个从节点连接进行数据读取。

****

****

### 哨兵模式

#### 为什么要有哨兵机制？

在Redis主从架构中，由于主从模式是读写分离的，如果主节点挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点进行数据同步了。因此，Redis提供了**哨兵（\*Sentinel\*）机制**，它的作用是实现**主从节点故障转移**。会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

哨兵节点主要负责三件事情：**监控、选主、通知**。

****

#### 如何判断主节点真的故障了？

哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。

主节点包含**主观下线和客观下线**两种状态，如果主节点没有在规定的时间响应哨兵的 PING 命令，哨兵就会将它们标记为「**主观下线**」。

> 这样的目的是为了减少对主节点的误判情况。
>
> 哨兵在部署时通常会部署多个哨兵，用多个节点部署成**哨兵集群**（*最少需要三台机器来部署哨兵集群*），**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**。

> 如何判断主节点客观下线？
>
> 当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，**做出赞成投票或者拒绝投票的响应。**当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。
>
> **注意：一般quorum值会设置为：哨兵数 / 2 + 1**

****

#### 由哪个哨兵执行故障转移？

当判断出主节点客观下线后，需要在哨兵集群中选出一个 leader，让 leader 来执行主从切换。

> **候选者如何选举成为 Leader？**
>
> 哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者。
>
> ****
>
> **候选者如何选举成为 Leader？(共识算法-raft算法)**
>
> 候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。
>
> 任何一个候选者成为leader必须满足两个条件：
>
> - 第一，拿到半数以上的赞成票；
> - 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。
>
> **注意1：可能同时多个哨兵判断主节点客观下线，所以可能有多个候选者。**
>
> **注意2：如果选举leader没有成功，一段时间后会进入下一个纪元，继续选举。**

****

#### 主从故障转移过程？

主从故障转移操作包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。
- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；

> **选取新的主节点过程**
>
> 选取新的主节点会先将网络状态不好的从节点过滤掉了，接下来要对所有从节点进行三轮考察：**优先级、复制进度、ID 号**。在进行每一轮考察的时候，哪个从节点优先胜出，就选择其作为新主节点。
>
> - 网络状态不好：Redis 有个叫 down-after-milliseconds * 10 配置项，其down-after-milliseconds 是主从节点断连的最大连接超时时间。如果从节点与主节点断连次数超过10次，则认为该从节点网络不好。
> - 第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前，
> - 第二轮考察：如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。即通过`slave_repl_offset 与master_repl_offset`判断。
> - 第三轮考察：如果优先级和下标都相同，就选择从节点 ID 较小的那个。
>
> ****
>
> **如何通知客户主节点更换？**
>
> 主要**通过 Redis 的发布者/订阅者机制来实现**的。每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息。

****

#### 哨兵集群如何组成？

搭建哨兵时，不需要填写其他哨兵的信息，那么它们是如何感知对方的，又是如何组成哨兵集群的？

**哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的**。在主从集群中，主节点上有一个名为`__sentinel__:hello`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

并且哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。

****

****

### 切片集群模式

当 Redis **缓存数据量大到一台服务器无法缓存时**，就需要使用 **Redis 切片集群**（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，**一个切片集群共有 16384 个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。

> 哈希槽如何映射到具体的Redis节点上呢？
>
> - **平均分配：** 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。
> - **手动分配：** 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。
>
> **注意：在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。**

****

### 集群脑裂导致数据丢失怎么办？

- **什么是脑裂？**

Redis主从架构中，一般是一主多从的，主节点提供写操作，从节点提供读操作。如果出现主节点与客户端网络连接良好，主节点与所有从节点哨兵网络连接出现问题。客户端依旧会向主节点写入数据(过程A)，导致主从数据不一致。哨兵此时会通过故障转移选取新的主节点。此时集群就有两个主节点了 —— **脑裂出现了**。

如果后续网络好了，那么旧的主节点将会被降级为从节点，并向新主节点请求数据同步，**因为第一次同步是全量同步的方式，此时的从节点会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题**。

> **解决方案**
>
> 在 Redis 的配置文件中有两个参数我们可以设置：
>
> - min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。
> - min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。
>
> 这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，**主库就不会再接收客户端的写请求了**。
>
> **等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。**
>
> ****
>
> 对于客户端，当客户端发现 master 不可写后，我们**可以采取降级措施，将数据暂时写入本地缓存和磁盘中**，在一段时间（等 master 恢复正常）后重新写入 master 来保证数据不丢失，**也可以将数据写入 kafka 消息队列**，等 master 恢复正常，再隔一段时间去消费 kafka 中的数据，让将数据重新写入 master 。

****

****

## Redis过期删除和内存淘汰

### Redis过期删除策略

Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。

> **如何判断key是否过期？**
>
> 每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。
>
> 当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：
>
> - 如果不在，则正常读取键值；
> - 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

Redis 使用的过期删除策略是「**惰性删除+定期删除**」这两种策略配和使用。

> 1. **什么是惰性删除?**
>
> 惰性删除策略的做法是，**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**
>
> 惰性删除策略的**优点**：
>
> - 因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。
>
> 惰性删除策略的**缺点**：
>
> - 如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。
>
> ****
>
> 2. **什么是定期删除？**
>
> 定期删除策略的做法是，**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**
>
> Redis 的定期删除的流程：
>
> - 从过期字典中随机抽取 20 个 key；
>
> - 检查这 20 个 key 是否过期，并删除已过期的 key；
>
> - 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。
>
> **当定期删除循环流程的时间到达了上限**，也会结束删除流程。
>
> 定期删除策略的**优点**：
>
> - 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。
>
> 定期删除策略的**缺点**：
>
> - 难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。

****

### Redis持久化时，对过期键如何处理？

Redis持久化有两种方式，分别讨论

RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。

> **RDB 文件生成阶段**：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，**过期的键「不会」被保存到新的 RDB 文件中**。
>
> **RDB 加载阶段**：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况
>
> - **如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中**。
> - **如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中**。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。

AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。

> **AOF 文件写入阶段**：当 Redis 以 AOF 模式持久化时，**如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值**。
>
> **AOF 重写阶段**：执行 AOF 重写时，会对 Redis 中的键值对进行检查，**已过期的键不会被保存到重写后的 AOF 文件中**。

****

### Redis主从模式下， 对过期键如何处理？

当 Redis 运行在主从模式下时，**从库不会进行过期扫描，从库对过期的处理是被动的**。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。

从库的过期键处理依靠主服务器控制，**主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库**，从库通过执行这条 del 指令来删除过期的 key。

****

### Redis内存淘汰策略

当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用**内存淘汰策略**删除符合条件的 key，以此来保障 Redis 高效的运行。

#### Redis内存淘汰策略有哪些？

Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。

1. **不进行数据淘汰的策略**

**noeviction**（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果**有新的数据写入，则会触发 OOM**，但是如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作。

2. **进行数据淘汰的策略**

又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。

> 在设置了过期时间的数据中进行淘汰：
>
> - **volatile-random**：随机淘汰设置了过期时间的任意键值；
>
> - **volatile-ttl**：优先淘汰更早过期的键值。
> - **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
> - **volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；
>
> ****
>
> 在所有数据范围内进行淘汰：
>
> - **allkeys-random**：随机淘汰任意键值;
> - **allkeys-lru**：淘汰整个键值中最久未使用的键值；
> - **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

****

#### LRU和LFU有什么区别？

> 什么是LRU算法？

**LRU** 全称是 Least Recently Used 翻译为**最近最少使用**，会选择淘汰最近最少使用的数据。传统的LRU算法通过链表来实现，最近被访问的对象会被移动到链表头，链表尾则表示最久未被使用的元素。

传统的 LRU 算法存在两个问题：

- 需要用链表管理所有的缓存数据，这会带来额外的空间开销；
- 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。

> Redis如何实现LRU算法？

Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**。

当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。

****

但是，LRU算法有一个问题，即**无法解决缓存污染问题**。因此Redis 4.0 之后引入了 LFU 算法来解决这个问题。

> 什么是LFU算法？

LFU 全称是 Least Frequently Used 翻译为**最近最不常用**，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。

> Redis如何实现LFU算法？

Redis 对象头中有一个lru 字段，在LRU算法中，用于记录时间戳，在LFU算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储ldt（key的访问时间戳），低 8bit 存储logc（key的访问频次）。

**注意：访问频次不单单是访问次数，而是访问频次，会随时间推移而衰减**。在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大。对 logc 做完衰减操作后，就开始对 logc 进行增加操作，增加操作并不是单纯的+1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加。

****

****

## Redis缓存设计

### 什么是缓存雪崩、击穿、穿透？

下面是总结表格

![image-20230222151451602](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230222151451602.png)

****

#### 缓存雪崩

为了保证缓存中的数据与数据库中的数据一致性，会给 Redis 里的数据设置过期时间。那么，当**大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机**时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是**缓存雪崩**的问题。

![image-20230222150231126](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230222150231126.png)

> **大量数据同时过期而引发的缓存雪崩**，常见的应对策略有如下几种：
>
> - 均匀设置过期时间；
> - 互斥锁；
> - 双 key 策略；
> - 后台更新缓存；
>
> ****
>
> 1. **均匀设置过期时间**
>
> 可以在对缓存数据设置过期时间时，**给这些数据的过期时间加上一个随机数**，这样就保证数据不会在同一时间过期。
>
> 2. **互斥锁(singleflight)**
>
> 当业务线程在处理用户请求时，**如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存**（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
>
> 实现互斥锁的时候，最好设置**超时时间,** 防止请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。
>
> 该策略的缺陷就是**大量请求被锁阻塞住**。
>
> 3. **双key策略**
>
> 对缓存数据可以使用两个 key，一个是**主 key，会设置过期时间**，一个是**备 key，不会设置过期**，它们只是 key 不一样，但是 value 值是一样的，相当于给缓存数据做了个副本。
>
> 当业务线程访问不到「主 key 」的缓存数据时，就直接返回「备 key 」的缓存数据，然后在更新缓存的时候，**同时更新「主 key 」和「备 key 」的数据。**
>
> 双 key 策略的好处是，当主 key 过期了，有大量请求获取缓存数据的时候，直接返回备 key 的数据，这样可以快速响应请求。
>
> 4. **后台更新缓存**
>
> 业务线程不再负责更新缓存，缓存也不设置有效期，而是**让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新**。
>
> 实际上缓存不设置有效期，仍然有可能因为内存紧张被淘汰，在被后台线程更新之前的这一段时间内，业务线程仍然可能读取不到数据。
>
> > 解决方式一：后台线程不仅负责定时更新缓存，而且也负责**频繁地检测缓存是否有效**，但是这种方式总归有一个时间间隔，用户体验不好。
> >
> > 解决方式二：在业务线程发现缓存数据失效后（缓存数据被淘汰），**通过消息队列发送一条消息通知后台线程更新缓存**，这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。

> 注意：通常是业务线程将数据更新到Redis缓存中
>
> **缓存预热**：就是在业务刚上线的时候，我们提前把数据缓起来，而不是等待用户访问才来触发缓存构建。

****

> **Redis 故障宕机而引发的缓存雪崩问题**，常见的应对方法有下面这几种：
>
> - 服务熔断或请求限流机制；
> - 构建 Redis 缓存高可靠集群；
>
> ****
>
> 1. **服务熔断或请求限流机制**
>
> 可以启动**服务熔断**机制，**暂停业务应用对缓存服务的访问，直接返回错误**，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。
>
> 服务熔断虽然保护了数据库的正常运行，但是全部业务都无法正常工作。为了减少对业务的影响，我们可以启用**请求限流**机制，**只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务**，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。
>
> 2. **构建Redis高可用集群**
>
> 通过**主从节点的方式构建 Redis 缓存高可靠集群**。如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。

****

#### 缓存击穿

被频地访问的数据被称为热点数据。如果缓存中的**某个热点数据过期**了，此时大量的请求访问了该热点数据，无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是**缓存击穿**的问题。

缓存击穿和缓存雪崩很相似，可以理解为缓存击穿是缓存雪崩的一个子集。

> 应对缓存击穿可以采取前面说到两种方案：
>
> - 互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
> - 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间

****

#### 缓存穿透

当用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是**缓存穿透**的问题。

缓存穿透的发生一般有这两种情况：

- 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；
- 黑客恶意攻击，故意大量访问某些读取不存在数据的业务；

> 应对缓存穿透的方案，常见的方案有三种。
>
> - 第一种方案，非法请求的限制;
> - 第二种方案，缓存空值或者默认值;
> - 第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；
>
> ****
>
> 1. **非法请求限制**
>
> 在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。
>
> 2. **缓存空值或默认值**
>
> 当我们线上业务发现缓存穿透的现象时，可以**针对查询的数据，在缓存中设置一个空值或者默认值**，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。
>
> 3. **使用布隆过滤器**
>
> 可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，**业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在**，如果不存在，就不用通过查询数据库来判断数据是否存在。
>
> 即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。
>
> > 布隆过滤器原理
> >
> > **布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。**当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。
> >
> > 布隆过滤器会通过 3 个操作完成标记：
> >
> > - 第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；
> > - 第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。
> > - 第三步，将每个哈希值在位图数组的对应位置的值设置为 1；
> >
> > 查询某个数据是否存在时，只需要查找位图中对应位置是否全为1即可。
> >
> > **由于哈希冲突的原因，查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据**。
> >
> > ![image-20230222151916635](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230222151916635.png)

****

### 如何设计缓存策略，可以动态缓存热点数据？

由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而**只是将其中一部分热点数据缓存起来**，所以我们要设计一个热点数据动态缓存的策略。

热点数据动态缓存的策略总体思路：**通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据**。

> 以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：
>
> - 先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；
> - 同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；
> - 这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。
>
> 在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。

****

### 常见的缓存更新策略(数据库和缓存保持一致性)？

常见的缓存更新策略共有3种：

- Cache Aside（旁路缓存）策略；
- Read/Write Through（读穿 / 写穿）策略；
- Write Back（写回）策略；

**注意：由于Redis不提供写入数据库和自动加载数据库中的数据的功能。因此，Redis 和 MySQL 的更新策略用的是 Cache Aside，另外两种策略应用不了。**

****

#### Cache Aside（旁路缓存）策略

Cache Aside（旁路缓存）策略是最常用的，**应用程序直接与「数据库、缓存」交互，并负责对缓存的维护**，该策略又可以细分为「读策略」和「写策略」。

![image-20230222155406639](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230222155406639.png)

**写策略的步骤：**

- 先更新数据库中的数据，再删除缓存中的数据。

**读策略的步骤：**

- 如果读取的数据命中了缓存，则直接返回数据；
- 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。

> **Cache Aside 策略适合读多写少的场景，不适合写多的场景**，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果业务对缓存命中率有严格的要求，**可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况**。那么可以考虑两种解决方案：
>
> > 注意：常规的「更新数据库+更新缓存」无论谁先都会在并发请求下出现数据不一致情况。
>
> - 一种做法是在更新数据时也更新缓存，只是在**更新缓存前先加一个分布式锁**，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；
> - 另一种做法同样也是在更新数据时更新缓存，只是**给缓存加一个较短的过期时间**，这样即使出现缓存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受

****

> 注意：写策略的步骤的顺序不能倒过来，即**不能先删除缓存再更新数据库**，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。
>
> > 注意：可以通过**延时双删**的策略来解决缓存不一致的问题。
> >
> > **要求更新数据库后，加入一个睡眠时间**，并且睡眠时间需要大于另外的请求「从数据库读取数据 + 写入缓存」的时间。
> >
> > 延时长度很难确定，所以基本不采用「先删缓存，再更新数据库，最后延时再删缓存的方式」。
>
> 如下例子：
>
> 假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。
>
> ![image-20230222155751800](https://narcissusblog-img.oss-cn-beijing.aliyuncs.com/uPic/file-2023-02/image-20230222155751800.png)
>
> ****
>
> **为什么「先更新数据库再删除缓存」不会有数据不一致的问题？**
>
> 理论上，也会出现数据不一致情况，**但是在实际中，这个问题出现的概率并不高。因为缓存的写入通常要远远快于数据库的写入。** 另外**还可以给缓存数据加上过期时间**，就算发生了缓存不一致，也会有过期时间兜底。
>
> > **如果出现了数据库写入成功，但是缓存删除阶段出错导致删除失败。** 有两种方法：
> >
> > - 重试机制。
> > - 订阅 MySQL binlog，再操作缓存。
> >
> > **这两种方式都是异步操作缓存。**
> >
> > ****
> >
> > 1. **重试机制**
> >
> > 可以引入**消息队列**将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。
> >
> > - 如果应用**删除缓存失败**，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是**重试机制**。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
> > - 如果**删除缓存成功**，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。
> >
> > 2. **订阅MySQL binlog，再操作缓存**
> >
> > 「先更新数据库，再删缓存」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。
> >
> > 于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除。

****

#### Read/Write Through（读穿 / 写穿）策略

Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。

> 1. **Read Through 策略**
>
> 先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。
>
> 2. **Write Through 策略**
>
> 当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：
>
> - 如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。
> - 如果缓存中数据不存在，直接更新数据库，然后返回；

Read Through/Write Through 策略的特点是由缓存节点而非应用程序来和数据库打交道，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库和自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略。

****

#### Write Back（写回）策略

Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。

> 实际上，Write Back（写回）策略也不能应用到我们常用的数据库和缓存的场景中，因为 **Redis 并没有异步更新数据库的功能。**

Write Back 是计算机体系结构中的设计，比如 CPU 的缓存、操作系统中文件系统的缓存都采用了 Write Back（写回）策略。**Write Back 策略特别适合写多的场景**，因为发生写操作的时候， 只需要更新缓存，就立马返回了。

**但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险**，因为缓存一般使用内存，所以一旦缓存机器断电，就会造成原本缓存中的脏数据丢失。

****

****

## Redis实战

### Redis大key如何处理？

**什么是大key?**

大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。一般而言，下面这两种情况被称为大 key：

- String 类型的值大于 10 KB；
- Hash、List、Set、ZSet 类型的元素的个数超过 5000个；

#### 大key的影响

大key会带来如下的影响：

- **客户端超时阻塞**。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
- **引发网络阻塞**。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
- **阻塞工作线程**。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
- **内存分布不均**。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。
- **持久化时阻塞主线程** ：在父进程`fork()`子进程复制页表时，和父进程发生写时复制是，由于大key占用内存大，会阻塞主线程过久。

#### 删除大key

> 如何查询到大key
>
> 1. **使用redis-cli --bigkeys 查找大key**
>
> 该方式只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey。并且对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。
>
> 2. **使用 SCAN 命令查找大 key**
> 2. **使用 RdbTools 工具查找大 key**

如果一次性删除大Key，会造成主线程阻塞。删除大Key可以通过如下两种方式：

- 分批次删除
- 异步删除（Redis 4.0版本以上）

> 从 Redis 4.0 版本开始，可以采用**异步删除**法，**用 unlink 命令代替 del 来删除**。这样 Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。



